# WandB Sweep Configuration for Hyperparameter Tuning
method: bayes  # 베이지안 최적화로 효율적인 탐색
metric:
  name: eval/rouge_avg  # ROUGE-1, ROUGE-2, ROUGE-L의 평균값 (실제 로그되는 메트릭 이름과 일치)
  goal: maximize        # ROUGE 점수이므로 최대화

parameters:
  "training.seed":
    min: 1
    max: 999999
    distribution: int_uniform
    
  "training.learning_rate":
    min: 0.00001
    max: 0.0005
    distribution: log_uniform_values
    
  "training.per_device_train_batch_size":
    values: [8, 16, 32, 48]
    
  "training.num_train_epochs":
    min: 5
    max: 20
    distribution: int_uniform
    
  "training.warmup_ratio":
    min: 0.0
    max: 0.2
    distribution: uniform
    
  "training.weight_decay":
    min: 0.0
    max: 0.1
    distribution: uniform
    
  "training.lr_scheduler_type":
    values: ["cosine", "linear", "polynomial"]
    
  "training.gradient_accumulation_steps":
    values: [1, 2, 4]
    
  "training.optim":
    values: ["adamw_torch", "adamw_torch_fused", "adafactor"]
    
  # Early Stopping parameters (성능에 직접 영향, 보수적 설정)
  "training.early_stopping_patience":
    min: 1
    max: 10
    distribution: int_uniform
    
  "training.early_stopping_threshold":
    min: 0.0001
    max: 0.1
    distribution: log_uniform_values
    
  # 수치 안정성 파라미터
  "training.fp16":
    values: [true, false]
 
  # 시퀀스 길이 파라미터: GPU Tensor Core 최적화를 위해 8의 배수로 제한 (q=8)
  # FP16 사용 시 8의 배수 정렬이 메모리 코어레싱과 Tensor Core 활용도를 향상시켜 최대 2.6배 성능 개선 가능
    
  "training.generation_max_length":
    min: 48
    max: 120
    distribution: q_uniform
    q: 8
    
  "inference.generate_max_length":
    min: 48
    max: 120
    distribution: q_uniform
    q: 8
    
  "tokenizer.decoder_max_len":
    min: 48
    max: 120
    distribution: q_uniform
    q: 8
    
  # 입력 텍스트 최대 길이: 메모리 사용량과 처리 성능의 균형점 탐색
  "tokenizer.encoder_max_len":
    min: 256
    max: 768
    distribution: q_uniform
    q: 8
    
  # 반복 n-gram 방지 파라미터: 텍스트 품질 향상을 위한 중요한 설정
  "inference.no_repeat_ngram_size":
    min: 2
    max: 5
    distribution: int_uniform
    
  # Beam Search 파라미터: 품질과 속도의 균형을 위한 빔 개수 설정
  "inference.num_beams":
    values: [1, 2, 4, 6, 8]

# Note: Early stopping is handled by the training script, not by WandB sweep configuration
  
# Command to run
command:
  - ${env}
  - python
  - wandb_sweep.py
  - ${args}