# WandB Sweep Configuration for Hyperparameter Tuning
method: bayes  # 베이지안 최적화로 효율적인 탐색
metric:
  name: eval/rouge_avg  # ROUGE-1, ROUGE-2, ROUGE-L의 평균값 (실제 로그되는 메트릭 이름과 일치)
  goal: maximize        # ROUGE 점수이므로 최대화

parameters:
  "training.learning_rate":
    min: 0.00001
    max: 0.0005
    distribution: log_uniform_values
    
  "training.per_device_train_batch_size":
    values: [8, 16, 32, 48]
    
  "training.num_train_epochs":
    min: 5
    max: 20
    distribution: int_uniform
    
  "training.warmup_ratio":
    min: 0.0
    max: 0.2
    distribution: uniform
    
  "training.weight_decay":
    min: 0.0
    max: 0.1
    distribution: uniform
    
  "training.lr_scheduler_type":
    values: ["cosine", "linear", "polynomial"]
    
  "training.gradient_accumulation_steps":
    values: [1, 2, 4]
    
  "training.optim":
    values: ["adamw_torch", "adamw_torch_fused", "adafactor"]
    
  # Early Stopping parameters (성능에 직접 영향, 보수적 설정)
  "training.early_stopping_patience":
    min: 1
    max: 10
    distribution: int_uniform
    
  "training.early_stopping_threshold":
    min: 0.0001
    max: 0.1
    distribution: log_uniform_values
    
  # 수치 안정성 파라미터
  "training.fp16":
    values: [true, false]
    
  # 참고: inference 관련 파라미터(num_beams, no_repeat_ngram_size 등)는 
  # 학습 시에는 사용되지 않으므로 하이퍼파라미터 스윕에서 제외
  
  # 시퀀스 길이 파라미터: GPU Tensor Core 최적화를 위해 8의 배수로 제한 (q=8)
  # FP16 사용 시 8의 배수 정렬이 메모리 코어레싱과 Tensor Core 활용도를 향상시켜 최대 2.6배 성능 개선 가능
    
  "training.generation_max_length":
    min: 48
    max: 120
    distribution: q_uniform
    q: 8
    
  "inference.generate_max_length":
    min: 48
    max: 120
    distribution: q_uniform
    q: 8
    
  "tokenizer.decoder_max_len":
    min: 48
    max: 120
    distribution: q_uniform
    q: 8

# Note: Early stopping is handled by the training script, not by WandB sweep configuration
  
# Command to run
command:
  - ${env}
  - python
  - wandb_sweep.py
  - ${args}