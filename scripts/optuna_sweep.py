#!/usr/bin/env python

import optuna
import subprocess
import json
import re
import os
import logging
import shutil
import time
import threading
from datetime import datetime


DISK_MONITOR_PATH = "/root/llm"  # ë””ìŠ¤í¬ ê¸°ì¤€ ê²½ë¡œ
DISK_LIMIT_GB = 10  # ë‚¨ì€ ê³µê°„ì´ 10GB ë¯¸ë§Œì´ë©´ ì‹¤í–‰ ì¤‘ë‹¨


def get_available_disk_gb(path: str = DISK_MONITOR_PATH) -> float:
    """ë””ìŠ¤í¬ ì‚¬ìš© ê°€ëŠ¥ ê³µê°„ì„ GB ë‹¨ìœ„ë¡œ ë°˜í™˜"""
    usage = shutil.disk_usage(path)
    return usage.free / (1024**3)


def monitor_disk_usage(trial_number: int, stop_event: threading.Event) -> None:
    """ë””ìŠ¤í¬ ì‚¬ìš© ê°€ëŠ¥ ê³µê°„ ëª¨ë‹ˆí„°ë§ - ë¶€ì¡± ì‹œ ì¦‰ì‹œ ì¢…ë£Œ"""
    warning_gb = 12
    while not stop_event.is_set():
        free_gb = get_available_disk_gb()
        if free_gb < warning_gb:
            logging.warning(f"âš ï¸ Trial {trial_number} - ì‚¬ìš© ê°€ëŠ¥ ë””ìŠ¤í¬ ê³µê°„ {free_gb:.1f}GB (ìœ„í—˜)")
        if free_gb < DISK_LIMIT_GB:
            logging.error(f"ğŸš¨ Trial {trial_number} - ì‚¬ìš© ê°€ëŠ¥ ë””ìŠ¤í¬ ê³µê°„ {free_gb:.1f}GB (í•œê³„ ì´í•˜)")
            os._exit(1)
        time.sleep(30)


def objective(trial):
    """Optuna ëª©ì  í•¨ìˆ˜"""

    # íŒŒë¼ë¯¸í„° ì œì•ˆ (ê³ ì„±ëŠ¥ ëª¨ë¸ 3ê°œ ê¸°ì¤€ìœ¼ë¡œ ì´ˆì •ë°€ íƒìƒ‰)
    # model_20250731_062917: Final Score 69.2073
    # model_20250731_113036: Final Score 69.2026  
    # model_20250731_120651: ROUGE-1 0.1587 (ìµœì‹  ê³ ì„±ëŠ¥)
    # ëª¨ë“  ëª¨ë¸ì´ config.yaml ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ìš°ìˆ˜í•œ ì„±ëŠ¥ ë‹¬ì„±
    learning_rate = trial.suggest_float('learning_rate', 8e-6, 1.2e-5, log=True)  # 1.0e-05 ì£¼ë³€ ë” ë„“ì€ íƒìƒ‰
    num_train_epochs = trial.suggest_categorical('num_train_epochs', [18, 19, 20, 21, 22])  # 20 epoch ì¤‘ì‹¬ í™•ì¥
    weight_decay = trial.suggest_float('weight_decay', 0.007, 0.013)  # 0.01 ì¤‘ì‹¬ í™•ì¥ëœ ì •ë°€ íƒìƒ‰
    per_device_train_batch_size = trial.suggest_categorical('per_device_train_batch_size', [16, 24, 32])  # GPU ë©”ëª¨ë¦¬ ê³ ë ¤ ì¶•ì†Œ
    warmup_ratio = trial.suggest_float('warmup_ratio', 0.08, 0.12)  # 0.1 ì¤‘ì‹¬ í™•ì¥ëœ ì •ë°€ íƒìƒ‰
    num_beams = trial.suggest_categorical('num_beams', [3, 4, 5, 6])  # 4 ì¤‘ì‹¬, ë” ë„“ì€ ë²”ìœ„
    
    # train.py ì§€ì› íŒŒë¼ë¯¸í„°ë§Œ ì¶”ê°€ (3ë²ˆì§¸ ëª¨ë¸ íŒ¨í„´ ë°˜ì˜)
    gradient_accumulation_steps = trial.suggest_categorical('gradient_accumulation_steps', [2, 3, 4])  # ë°°ì¹˜ í¬ê¸° ì¶•ì†Œë¡œ ì¦ê°€
    dropout = trial.suggest_float('dropout', 0.1, 0.2)  # ë“œë¡­ì•„ì›ƒ ë²”ìœ„ ì¶•ì†Œ

    params = {
        'learning_rate': learning_rate,
        'num_train_epochs': num_train_epochs,
        'weight_decay': weight_decay,
        'per_device_train_batch_size': per_device_train_batch_size,
        'warmup_ratio': warmup_ratio,
        'num_beams': num_beams,
        'gradient_accumulation_steps': gradient_accumulation_steps,
        'dropout': dropout,
    }

    # ë””ìŠ¤í¬ ì—¬ìœ  ê³µê°„ í™•ì¸
    available_gb = get_available_disk_gb()
    if available_gb < DISK_LIMIT_GB:
        logging.error(f"Trial {trial.number} - ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± ({available_gb:.1f}GB)")
        raise optuna.TrialPruned()

    print(f"\nğŸ§ª Trial {trial.number} ì‹œì‘")
    print(f"ğŸ“‹ íŒŒë¼ë¯¸í„°: {params}")
    print(f"ğŸ’¾ ì‚¬ìš© ê°€ëŠ¥ ë””ìŠ¤í¬: {available_gb:.1f}GB")

    stop_event = threading.Event()
    monitor_thread = threading.Thread(
        target=monitor_disk_usage,
        args=(trial.number, stop_event),
        daemon=True
    )
    monitor_thread.start()

    cmd = ["python", "src/models/train.py", "--config-path", "src/config/config.yaml"]

    for key, value in params.items():
        cmd.extend([f"--{key}", str(value)])

    try:
        result = subprocess.run(cmd, capture_output=True, text=True, cwd=".", timeout=3600)
        if result.returncode == 0:
            logging.info(f"Trial {trial.number} - í•™ìŠµ ì„±ê³µ")

            eval_cmd = ["python", "src/models/evaluate.py", "--model_path", "outputs/models/latest"]
            eval_result = subprocess.run(eval_cmd, capture_output=True, text=True, cwd=".", timeout=600)

            if eval_result.returncode == 0:
                match = re.search(r'Final Score: ([\d.]+)', eval_result.stdout)
                if match:
                    final_score = float(match.group(1))
                    print(f"âœ… Trial {trial.number} ì™„ë£Œ - Final Score: {final_score}")
                    logging.info(f"Trial {trial.number} - Final Score: {final_score}")
                    return final_score
                else:
                    logging.error(f"Trial {trial.number} - Final Score ì¶”ì¶œ ì‹¤íŒ¨")
                    raise optuna.TrialPruned()
            else:
                logging.error(f"Trial {trial.number} - í‰ê°€ ì‹¤íŒ¨")
                raise optuna.TrialPruned()
        else:
            logging.error(f"Trial {trial.number} - í•™ìŠµ ì‹¤íŒ¨")
            raise optuna.TrialPruned()

    except subprocess.TimeoutExpired:
        logging.error(f"Trial {trial.number} - íƒ€ì„ì•„ì›ƒ")
        raise optuna.TrialPruned()
    except Exception as e:
        print("ğŸ“„ train.py stdout:\n", result.stdout)
        print("ğŸ“„ train.py stderr:\n", result.stderr)
        logging.error(f"Trial {trial.number} - ì˜ˆì™¸ ë°œìƒ: {e}")
        raise optuna.TrialPruned()
    
    finally:
        stop_event.set()
        final_disk = get_available_disk_gb()
        logging.info(f"Trial {trial.number} ì¢…ë£Œ - ìµœì¢… ì‚¬ìš© ê°€ëŠ¥ ë””ìŠ¤í¬: {final_disk:.1f}GB")

def run_optuna_study(n_trials=10):
    """Optuna ìŠ¤í„°ë”” ì‹¤í–‰"""

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('optuna_baseline_optimization.log'),
            logging.StreamHandler()
        ]
    )

    available_gb = get_available_disk_gb()
    logging.info(f"ğŸš€ ìµœì í™” ì‹œì‘ - ì‚¬ìš© ê°€ëŠ¥ ë””ìŠ¤í¬: {available_gb:.1f}GB")

    if available_gb < DISK_LIMIT_GB:
        logging.error(f"ğŸš¨ ì‚¬ìš© ê°€ëŠ¥ ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±: {available_gb:.1f}GB")
        return None

    study_name = f"baseline_optuna_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    # ê³ ì„±ëŠ¥ ëª¨ë¸ 3ê°œ íŒ¨í„´ì— ë§ì¶˜ ê³ ê¸‰ ìƒ˜í”ŒëŸ¬ ì„¤ì •
    study = optuna.create_study(
        direction='maximize',
        study_name=study_name,
        sampler=optuna.samplers.TPESampler(
            n_startup_trials=5,  # ë” ë§ì€ ì‹œì‘ trialë¡œ ì•ˆì •ì„± í™•ë³´
            n_ei_candidates=48,  # ë” ë§ì€ í›„ë³´ íƒìƒ‰
            seed=42,
            multivariate=True,  # íŒŒë¼ë¯¸í„°ê°„ ìƒê´€ê´€ê³„ ê³ ë ¤
            group=True  # ì¹´í…Œê³ ë¦¬ì»¬ íŒŒë¼ë¯¸í„° ê·¸ë£¹í™”
        ),
        pruner=optuna.pruners.MedianPruner(
            n_startup_trials=4,  # 3ê°œ ëª¨ë¸ íŒ¨í„´ ê¸°ë°˜ ì¡°ê¸° ê°€ì§€ì¹˜ê¸°
            n_warmup_steps=2,
            interval_steps=1
        )
    )

    print(f"ğŸš€ Optuna ìŠ¤í„°ë”” ì‹œì‘: {study_name}")
    print(f"ğŸ“Š ì´ {n_trials}ë²ˆì˜ trial ì˜ˆì •")
    print(f"ğŸ“‹ config.yaml ê¸°ë°˜ + ê³ ì„±ëŠ¥ ëª¨ë¸ 3ê°œ íŒ¨í„´ ë°˜ì˜")
    print(f"ğŸ¯ ëª©í‘œ: Final Score 69.2+ (ìµœê³  ëª¨ë¸ë“¤ ê¸°ì¤€)")
    print(f"ğŸ’¾ ë””ìŠ¤í¬ ì—¬ìœ  ê³µê°„ ì œí•œ: {DISK_LIMIT_GB}GB\n")

    study.optimize(objective, n_trials=n_trials)

    print("\nğŸ“Š ìµœì í™” ê²°ê³¼")
    try:
        print(f"ğŸ† ìµœê³  ì ìˆ˜: {study.best_value:.4f}")
        print(f"ğŸ¯ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€: {'âœ… ë‹¬ì„±!' if study.best_value >= 69.0 else 'ğŸ“ˆ ê°œì„  í•„ìš”'}")
        print("ğŸ›ï¸ ìµœì  íŒŒë¼ë¯¸í„°:")
        for k, v in study.best_params.items():
            print(f"  - {k}: {v}")
        
        # ìƒìœ„ 3ê°œ trial ì •ë³´ í‘œì‹œ
        if len(study.trials) >= 3:
            print("\nğŸ¥‡ ìƒìœ„ 3ê°œ Trial:")
            sorted_trials = sorted([t for t in study.trials if t.value is not None], 
                                 key=lambda x: x.value, reverse=True)[:3]
            for i, trial in enumerate(sorted_trials, 1):
                print(f"  {i}. Trial {trial.number}: {trial.value:.4f}")
    except ValueError:
        print("âš ï¸ ì„±ê³µí•œ trialì´ ì—†ìŠµë‹ˆë‹¤.")

    results_file = f"optuna_baseline_results_{study_name}.json"
    try:
        with open(results_file, 'w') as f:
            # ìƒìœ„ trials ì •ë³´ ì¶”ê°€
            top_trials = []
            if study.trials:
                sorted_trials = sorted([t for t in study.trials if t.value is not None], 
                                     key=lambda x: x.value, reverse=True)[:5]
                top_trials = [{'trial_number': t.number, 'score': t.value, 'params': t.params} 
                            for t in sorted_trials]
            
            json.dump({
                'study_name': study_name,
                'reference_models': {
                    'model_20250731_062917': {'final_score': 69.2073, 'note': 'ìµœê³  ì„±ëŠ¥'},
                    'model_20250731_113036': {'final_score': 69.2026, 'note': 'ì•ˆì •ì  ê³ ì„±ëŠ¥'},
                    'model_20250731_120651': {'rouge_1': 0.1587, 'note': 'ìµœì‹  ê³ ì„±ëŠ¥ ëª¨ë¸'}
                },
                'best_score': study.best_value if study.trials else None,
                'best_params': study.best_params if study.trials else None,
                'top_5_trials': top_trials,
                'config_base': 'config.yaml',
                'disk_limit_gb': DISK_LIMIT_GB,
                'total_trials': len(study.trials),
                'successful_trials': len([t for t in study.trials if t.value is not None])
            }, f, indent=2)
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {results_file}")
    except Exception as e:
        logging.error(f"ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    return study


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¯ Optuna Hyperparameter Optimization ì‹œì‘")
    print("ê³ ì„±ëŠ¥ ëª¨ë¸ 3ê°œ íŒ¨í„´ ê¸°ë°˜ ì´ˆì •ë°€ ìµœì í™”")
    print("ë””ìŠ¤í¬ ì—¬ìœ  ê³µê°„ ê¸°ì¤€ ìµœì í™”")

    total_gb = shutil.disk_usage(DISK_MONITOR_PATH).total / (1024**3)
    free_gb = get_available_disk_gb()
    used_gb = total_gb - free_gb

    print(f"\nğŸ’¾ ë””ìŠ¤í¬ ìƒíƒœ ({DISK_MONITOR_PATH} ê¸°ì¤€):")
    print(f"   - ì „ì²´: {total_gb:.1f}GB")
    print(f"   - ì‚¬ìš©ì¤‘: {used_gb:.1f}GB")
    print(f"   - ì‚¬ìš©ê°€ëŠ¥: {free_gb:.1f}GB")
    print(f"   - ì œí•œ: {DISK_LIMIT_GB}GB\n")

    if free_gb < DISK_LIMIT_GB:
        print("âŒ ì‚¬ìš© ê°€ëŠ¥ ê³µê°„ì´ ë¶€ì¡±í•´ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    study = run_optuna_study(n_trials=12)   # ê³ ì„±ëŠ¥ ëª¨ë¸ 3ê°œ ê¸°ì¤€ í™•ì¥ëœ íƒìƒ‰
    if study:
        print("\nğŸ‰ Optuna ìµœì í™” ì™„ë£Œ!")
    else:
        print("\nâŒ ë””ìŠ¤í¬ ë¶€ì¡±ìœ¼ë¡œ ìµœì í™” ì‹¤íŒ¨")


if __name__ == "__main__":
    main()


