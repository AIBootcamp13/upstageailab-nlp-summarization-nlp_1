"""
BART ê¸°ë°˜ ëŒ€í™” ìš”ì•½ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
baseline.ipynbì™€ config.yamlì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„
+ sweep.yaml í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì§€ì›
"""

import os
import sys
import yaml
import torch
import argparse
from rouge import Rouge
from torch.utils.data import Dataset
from transformers import (
    AutoTokenizer, 
    BartForConditionalGeneration, 
    BartConfig,
    Seq2SeqTrainer, 
    Seq2SeqTrainingArguments,
    EarlyStoppingCallback
)
from pathlib import Path
import pandas as pd
from datasets import Dataset, load_dataset
import random, numpy as np
from transformers import set_seed as hf_set_seed

# í˜„ì¬ íŒŒì¼ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ data ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = Path(current_dir).parent.parent
sys.path.append(str(project_root / "src"))
sys.path.append(str(project_root / "src" / "data"))

# ì´ì œ src ê²½ë¡œê°€ sys.path ì— ë“±ë¡ë˜ì—ˆìœ¼ë¯€ë¡œ utils ë¥¼ ì•ˆì „í•˜ê²Œ import
from utils.postprocess import postprocess
from utils.metrics import calculate_rouge_scores


def set_all_seeds(seed: int):
    """random / numpy / torch / HF transformers ì‹œë“œ ê³ ì •"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    hf_set_seed(seed)


def load_config_with_overrides(config_path=None, overrides=None):
    """ì„¤ì • íŒŒì¼ ë¡œë“œ ë° sweep íŒŒë¼ë¯¸í„° ì˜¤ë²„ë¼ì´ë“œ"""
    # Config íŒŒì¼ ê²½ë¡œ ì„¤ì •
    if config_path is None:
        config_path = os.path.join(project_root, "src", "config", "config.yaml")
    
    print(f"ğŸ“ ì„¤ì • íŒŒì¼ ë¡œë“œ: {config_path}")
    with open(config_path, "r") as file:
        config = yaml.safe_load(file)
    
    # WandB sweepì—ì„œ ì „ë‹¬ëœ íŒŒë¼ë¯¸í„°ë“¤ë¡œ config ì˜¤ë²„ë¼ì´ë“œ
    if overrides:
        print(f"ğŸ”„ Sweep íŒŒë¼ë¯¸í„° ì˜¤ë²„ë¼ì´ë“œ: {overrides}")
        
        # training ì„¹ì…˜ íŒŒë¼ë¯¸í„°ë“¤
        if 'learning_rate' in overrides:
            config['training']['learning_rate'] = overrides['learning_rate']
        if 'num_train_epochs' in overrides:
            config['training']['num_train_epochs'] = overrides['num_train_epochs']
        if 'weight_decay' in overrides:
            config['training']['weight_decay'] = overrides['weight_decay']
        if 'per_device_train_batch_size' in overrides:
            config['training']['per_device_train_batch_size'] = overrides['per_device_train_batch_size']
        if 'gradient_accumulation_steps' in overrides:
            config['training']['gradient_accumulation_steps'] = overrides['gradient_accumulation_steps']
            
        # inference ì„¹ì…˜ íŒŒë¼ë¯¸í„°ë“¤
        if 'num_beams' in overrides:
            config['inference']['num_beams'] = overrides['num_beams']
            
        # ëª¨ë¸ dropout (ëª¨ë¸ configì— ì ìš©)
        if 'dropout' in overrides:
            config['model_overrides'] = config.get('model_overrides', {})
            config['model_overrides']['dropout'] = overrides['dropout']
            
        # ì¶”ê°€ training íŒŒë¼ë¯¸í„°ë“¤
        if 'warmup_ratio' in overrides:
            config['training']['warmup_ratio'] = overrides['warmup_ratio']
        if 'label_smoothing' in overrides:
            config['training']['label_smoothing_factor'] = overrides['label_smoothing']
        if 'length_penalty' in overrides:
            config['inference']['length_penalty'] = overrides['length_penalty']
        if 'repetition_penalty' in overrides:
            config['inference']['repetition_penalty'] = overrides['repetition_penalty']
        if 'generation_max_length' in overrides:
            config['training']['generation_max_length'] = overrides['generation_max_length']
    
    return config


def compute_metrics(config, tokenizer, pred):
    """í‰ê°€ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜"""
    predictions, labels = pred.predictions, pred.label_ids

    # ë””ì½”ë”©
    predictions[predictions == -100] = tokenizer.pad_token_id
    labels[labels == -100] = tokenizer.pad_token_id
    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)

    # í›„ì²˜ë¦¬
    remove_tokens = config['inference']['remove_tokens']
    postprocessed_preds = [postprocess(pred, remove_tokens) for pred in decoded_preds]
    postprocessed_labels = [[label] for label in decoded_labels]

    # ìƒˆë¡œìš´ metric í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì ìˆ˜ ê³„ì‚°
    result = calculate_rouge_scores(postprocessed_preds, postprocessed_labels)

    # ë¡œê·¸ ì¶œë ¥
    print("\n" + "="*10, "ROUGE Scores", "="*10)
    print(result)
    print("="*35 + "\n")

    return result


def prepare_train_dataset(config, data_path, tokenizer):
    """í•™ìŠµ ë°ì´í„°ì…‹ ì¤€ë¹„"""
    train_file_path = os.path.join(data_path, 'train.csv')
    val_file_path = os.path.join(data_path, 'dev.csv')

    # CSV íŒŒì¼ì„ pandas DataFrameìœ¼ë¡œ ë¡œë“œ
    train_df = pd.read_csv(train_file_path)
    val_df = pd.read_csv(val_file_path)

    # pandas DataFrameì„ Hugging Face Dataset ê°ì²´ë¡œ ë³€í™˜
    train_dataset = Dataset.from_pandas(train_df)
    val_dataset = Dataset.from_pandas(val_df)
    
    print('-' * 150)
    print(f'train_data:\n {train_dataset[0]["dialogue"]}')
    print(f'train_label:\n {train_dataset[0]["summary"]}')
    print('-' * 150)
    print(f'val_data:\n {val_dataset[0]["dialogue"]}')
    print(f'val_label:\n {val_dataset[0]["summary"]}')

    def tokenize_function(examples):
        # ëª¨ë¸ ì…ë ¥(ì¸ì½”ë”) í† í¬ë‚˜ì´ì§•
        model_inputs = tokenizer(
            examples['dialogue'],
            max_length=config['tokenizer']['encoder_max_len'],
            truncation=True,
            padding='max_length'
        )
        
        # ë ˆì´ë¸”(ë””ì½”ë” ì¶œë ¥) í† í¬ë‚˜ì´ì§•
        labels = tokenizer(
            text_target=examples['summary'],
            max_length=config['tokenizer']['decoder_max_len'],
            truncation=True,
            padding='max_length'
        )
        
        model_inputs["labels"] = labels["input_ids"]
        return model_inputs

    # map í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ì…‹ ì „ì²´ì— í† í¬ë‚˜ì´ì§• ì ìš©
    # batched=Trueë¡œ ì„¤ì •í•˜ì—¬ ì—¬ëŸ¬ ìƒ˜í”Œì„ í•œ ë²ˆì— ì²˜ë¦¬í•´ ì†ë„ í–¥ìƒ
    tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)
    tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)

    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
    tokenized_train_dataset = tokenized_train_dataset.remove_columns(train_dataset.column_names)
    tokenized_val_dataset = tokenized_val_dataset.remove_columns(val_dataset.column_names)

    print('-' * 10, 'Make dataset complete', '-' * 10)
    return tokenized_train_dataset, tokenized_val_dataset


def load_tokenizer_and_model_for_train(config, device):
    """í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¡œë“œ"""
    print('-' * 10, 'Load tokenizer & model', '-' * 10)
    print('-' * 10, f'Model Name : {config["general"]["model_name"]}', '-' * 10)
    
    model_name = config['general']['model_name']
    bart_config = BartConfig().from_pretrained(model_name)
    
    # sweepì—ì„œ ì§€ì •ëœ dropout ê°’ì´ ìˆìœ¼ë©´ ì ìš©
    if 'model_overrides' in config and 'dropout' in config['model_overrides']:
        bart_config.dropout = config['model_overrides']['dropout']
        bart_config.attention_dropout = config['model_overrides']['dropout']
        print(f"ğŸ¯ Dropout ì„¤ì •: {config['model_overrides']['dropout']}")
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    generate_model = BartForConditionalGeneration.from_pretrained(
        config['general']['model_name'], 
        config=bart_config
    )

    # íŠ¹ìˆ˜ í† í° ì¶”ê°€
    special_tokens_dict = {'additional_special_tokens': config['tokenizer']['special_tokens']}
    tokenizer.add_special_tokens(special_tokens_dict)

    # ëª¨ë¸ í¬ê¸° ì¡°ì • ë° ë””ë°”ì´ìŠ¤ ì´ë™
    generate_model.resize_token_embeddings(len(tokenizer))
    generate_model.to(device)
    
    print(f"Model config: {generate_model.config}")
    print(f"Tokenizer vocab size: {len(tokenizer)}")
    print('-' * 10, 'Load tokenizer & model complete', '-' * 10)
    
    return generate_model, tokenizer


def setup_training_arguments(config):
    """í•™ìŠµ ì¸ìˆ˜ ì„¤ì •"""
    print('-' * 10, 'Make training arguments', '-' * 10)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = config['general']['output_dir']
    os.makedirs(output_dir, exist_ok=True)
    
    training_args = Seq2SeqTrainingArguments(
        output_dir=output_dir,
        overwrite_output_dir=config['training']['overwrite_output_dir'],
        num_train_epochs=config['training']['num_train_epochs'],
        learning_rate=config['training']['learning_rate'],
        per_device_train_batch_size=config['training']['per_device_train_batch_size'],
        per_device_eval_batch_size=config['training']['per_device_eval_batch_size'],
        warmup_ratio=config['training']['warmup_ratio'],
        weight_decay=config['training']['weight_decay'],
        lr_scheduler_type=config['training']['lr_scheduler_type'],
        optim=config['training']['optim'],
        gradient_accumulation_steps=config['training']['gradient_accumulation_steps'],
        evaluation_strategy=config['training']['eval_strategy'],
        save_strategy=config['training']['save_strategy'],
        save_total_limit=config['training']['save_total_limit'],
        fp16=config['training']['fp16'],
        load_best_model_at_end=config['training']['load_best_model_at_end'],
        seed=config['training']['seed'],
        logging_dir=config['training']['logging_dir'],
        logging_strategy=config['training']['logging_strategy'],
        predict_with_generate=config['training']['predict_with_generate'],
        generation_max_length=config['tokenizer']['decoder_max_len'],  # decoder_max_lenê³¼ í†µì¼
        generation_num_beams=config['inference']['num_beams'],  # sweepì—ì„œ ì¡°ì • ê°€ëŠ¥
        do_train=config['training']['do_train'],
        do_eval=config['training']['do_eval'],
        report_to=config['training']['report_to'],
        metric_for_best_model='final_score',
        greater_is_better=True,  # final_scoreê°€ ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ëª¨ë¸
        save_safetensors=True,  # safetensors í˜•íƒœë¡œ ì €ì¥
        label_smoothing_factor=config['training'].get('label_smoothing_factor', 0.0),
    )
    
    print('-' * 10, 'Make training arguments complete', '-' * 10)
    return training_args


def setup_wandb(config, is_sweep=False):
    """WandB ì´ˆê¸°í™” (ë¹„í™œì„±í™”ë¨)"""
    pass


def create_trainer(config, model, tokenizer, train_dataset, val_dataset, training_args):
    """Trainer ìƒì„±"""
    print('-' * 10, 'Make trainer', '-' * 10)

    # EarlyStopping ì½œë°±
    early_stopping_callback = EarlyStoppingCallback(
        early_stopping_patience=config['training']['early_stopping_patience'],
        early_stopping_threshold=config['training']['early_stopping_threshold']
    )

    # Trainer í´ë˜ìŠ¤ ì •ì˜
    trainer = Seq2SeqTrainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        compute_metrics=lambda pred: compute_metrics(config, tokenizer, pred),
        callbacks=[early_stopping_callback]
    )
    
    print('-' * 10, 'Make trainer complete', '-' * 10)
    return trainer


def save_final_model(config, trainer, tokenizer):
    """ìµœì¢… ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥"""
    print("ğŸš€ ìµœì¢… ëª¨ë¸ ì €ì¥ ì‹œì‘...")
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ í¬í•¨í•œ ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    from datetime import datetime
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    timestamped_model_dir = f"model_{timestamp}"
    final_model_path = os.path.join(config['general']['output_dir'], timestamped_model_dir)
    final_model_abs_path = os.path.abspath(final_model_path)
    os.makedirs(final_model_abs_path, exist_ok=True)
    
    # 'latest' ì‹¬ë³¼ë¦­ ë§í¬ ìƒì„± (ê°€ì¥ ìµœê·¼ ëª¨ë¸)
    latest_link_path = os.path.join(config['general']['output_dir'], "latest")
    latest_link_abs_path = os.path.abspath(latest_link_path)
    
    # ê¸°ì¡´ latest ë§í¬ê°€ ìˆë‹¤ë©´ ì œê±°
    if os.path.exists(latest_link_abs_path) or os.path.islink(latest_link_abs_path):
        os.remove(latest_link_abs_path)
    
    # ìƒˆë¡œìš´ latest ë§í¬ ìƒì„±
    os.symlink(timestamped_model_dir, latest_link_abs_path)
    
    # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥
    trainer.save_model(final_model_abs_path)
    tokenizer.save_pretrained(final_model_abs_path)
    
    # ì„¤ì • íŒŒì¼ë„ í•¨ê»˜ ì €ì¥
    config_save_path = os.path.join(final_model_abs_path, "training_config.yaml")
    with open(config_save_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    print(f"âœ… ëª¨ë¸ ì €ì¥: {timestamped_model_dir}")
    print(f"ğŸ”— latest â†’ {timestamped_model_dir}")
    
    return final_model_abs_path, timestamped_model_dir


def update_best_model(config, current_model_path, model_dir_name, trainer):
    """í˜„ì¬ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ì—¬ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì—…ë°ì´íŠ¸"""
    try:
        # í˜„ì¬ ëª¨ë¸ í‰ê°€
        current_metrics = trainer.evaluate()
        current_score = current_metrics.get('eval_rouge_1', 0.0)
        
        print(f"[INFO] í˜„ì¬ ëª¨ë¸ ì ìˆ˜: {current_score:.4f}, ìµœê³  ì ìˆ˜: ì—…ë°ì´íŠ¸ ì˜ˆì •")
        
        # ì„±ëŠ¥ ê¸°ë¡ íŒŒì¼ ê²½ë¡œ
        models_dir = config['general']['output_dir']
        best_score_file = os.path.join(models_dir, "best_score.txt")
        best_model_info_file = os.path.join(models_dir, "best_model_info.txt")
        best_link_path = os.path.join(models_dir, "best")
        best_link_abs_path = os.path.abspath(best_link_path)
        
        # ì´ì „ ìµœê³  ì ìˆ˜ ì½ê¸°
        best_score = 0.0
        if os.path.exists(best_score_file):
            try:
                with open(best_score_file, 'r') as f:
                    best_score = float(f.read().strip())
            except:
                best_score = 0.0
        
        # í˜„ì¬ ëª¨ë¸ì´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ë©´ ì—…ë°ì´íŠ¸
        if current_score > best_score:
            print(f"ğŸ† NEW BEST: {current_score:.4f} (ì´ì „: {best_score:.4f})")
            
            # ìµœê³  ì ìˆ˜ ì €ì¥
            with open(best_score_file, 'w') as f:
                f.write(str(current_score))
            
            # ìµœê³  ëª¨ë¸ ì •ë³´ ì €ì¥
            with open(best_model_info_file, 'w') as f:
                f.write(f"model_dir: {model_dir_name}\n")
                f.write(f"rouge_1: {current_score:.4f}\n")
                f.write(f"timestamp: {model_dir_name.replace('model_', '')}\n")
            
            # ê¸°ì¡´ best ë§í¬ ì œê±°
            if os.path.exists(best_link_abs_path) or os.path.islink(best_link_abs_path):
                os.remove(best_link_abs_path)
            
            # ìƒˆë¡œìš´ best ë§í¬ ìƒì„±
            os.symlink(model_dir_name, best_link_abs_path)
            print(f"ğŸ”— best â†’ {model_dir_name}")
            
        else:
            if os.path.exists(best_link_abs_path):
                current_best = os.readlink(best_link_abs_path)
                print(f"[INFO] í˜„ì¬ ëª¨ë¸ ì ìˆ˜: {current_score:.4f}, ìµœê³  ì ìˆ˜: {best_score:.4f}")
                print("ìµœê³ ìŠ¤ì½”ì–´ì˜ ì—…ë°ì´íŠ¸ëŠ” ì—†ì—ˆìŠµë‹ˆë‹¤.")
            else:
                # best ë§í¬ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ëª¨ë¸ì„ bestë¡œ ì„¤ì •
                print(f"ğŸ† FIRST MODEL: {current_score:.4f}")
                with open(best_score_file, 'w') as f:
                    f.write(str(current_score))
                with open(best_model_info_file, 'w') as f:
                    f.write(f"model_dir: {model_dir_name}\n")
                    f.write(f"rouge_1: {current_score:.4f}\n")
                    f.write(f"timestamp: {model_dir_name.replace('model_', '')}\n")
                os.symlink(model_dir_name, best_link_abs_path)
                print(f"ğŸ”— best â†’ {model_dir_name}")
        
    except Exception as e:
        print(f"âŒ ì„±ëŠ¥ í‰ê°€ ì‹¤íŒ¨: {e}")


def main(config_path=None, sweep_config=None):
    """ë©”ì¸ í•™ìŠµ í•¨ìˆ˜"""
    print("ğŸš€ [1/8] ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹œì‘...")
    
    # sweep íŒŒë¼ë¯¸í„° í™•ì¸
    is_sweep = sweep_config is not None
    
    # ì„¤ì • ë¡œë“œ
    config = load_config_with_overrides(config_path, sweep_config)
    print("âœ… [1/8] ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ")

    # ì „ì—­ ì‹œë“œ ê³ ì •
    seed_val = config.get('general', {}).get('seed', config['training'].get('seed', 42))
    set_all_seeds(seed_val)
    print(f"ğŸ”’ ì „ì—­ ì‹œë“œ ê³ ì •: {seed_val}")

    # ì‚¬ìš©í•  device ì •ì˜
    print("ğŸš€ [2/8] ë””ë°”ì´ìŠ¤ ì„¤ì • ì‹œì‘...")
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    print(f"---------- device : {device} ----------")
    print(f"PyTorch version: {torch.__version__}")
    print("âœ… [2/8] ë””ë°”ì´ìŠ¤ ì„¤ì • ì™„ë£Œ")

    # ì‚¬ìš©í•  ëª¨ë¸ê³¼ tokenizer ë¶ˆëŸ¬ì˜¤ê¸°
    print("ğŸš€ [3/8] ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹œì‘...")
    generate_model, tokenizer = load_tokenizer_and_model_for_train(config, device)
    print(f"Tokenizer special tokens: {tokenizer.special_tokens_map}")
    print("âœ… [3/8] ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ")

    # í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
    print("ğŸš€ [4/8] ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹œì‘...")
    preprocess_version = config['general'].get('preprocess_version', 'v1')
    processed_data_path = os.path.join(project_root, "data", "processed", preprocess_version)
    train_inputs_dataset, val_inputs_dataset = prepare_train_dataset(config, processed_data_path, tokenizer)
    print("âœ… [4/8] ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ")

    # í•™ìŠµ ì¸ìˆ˜ ì„¤ì •
    print("ğŸš€ [5/8] í•™ìŠµ ì„¤ì • ì‹œì‘...")
    training_args = setup_training_arguments(config)
    # setup_wandb(config, is_sweep)  # wandb ë¹„í™œì„±í™”
    print("âœ… [5/8] í•™ìŠµ ì„¤ì • ì™„ë£Œ")

    # Trainer í´ë˜ìŠ¤ ìƒì„±
    print("ğŸš€ [6/8] íŠ¸ë ˆì´ë„ˆ ì„¤ì • ì‹œì‘...")
    trainer = create_trainer(config, generate_model, tokenizer, train_inputs_dataset, val_inputs_dataset, training_args)
    print("âœ… [6/8] íŠ¸ë ˆì´ë„ˆ ì„¤ì • ì™„ë£Œ")
    
    # ëª¨ë¸ í•™ìŠµ ì‹œì‘
    print("ğŸš€ [7/8] ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    print("â¡ï¸ ìƒˆë¡œìš´ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    results = trainer.train()
    print("âœ… [7/8] ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

    # ìµœì¢… ëª¨ë¸ ì €ì¥ ë° ì •ë¦¬
    print("ğŸš€ [8/8] ìµœì¢… ì •ë¦¬ ì‹œì‘...")
    
    # ëª¨ë¸ ì €ì¥
    final_model_path, model_dir_name = save_final_model(config, trainer, tokenizer)
    
    # ì„±ëŠ¥ í‰ê°€ ë° best ëª¨ë¸ ì—…ë°ì´íŠ¸
    update_best_model(config, final_model_path, model_dir_name, trainer)
    
    # WandB ë¹„í™œì„±í™”ë¨
    
    print("âœ… [8/8] ìµœì¢… ì •ë¦¬ ì™„ë£Œ. ëª¨ë“  í”„ë¡œì„¸ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ëë‚¬ìŠµë‹ˆë‹¤.")
    
    # ìµœì¢… ìš”ì•½ (ê°„ê²°í•˜ê²Œ)
    print(f"\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥: {os.path.relpath(final_model_path)}")
    print(f"ğŸš€ í‰ê°€: python src/models/evaluate.py --model_path outputs/models/best")
    print(f"ğŸš€ ì¶”ë¡ : python src/models/infer.py --model_path outputs/models/best")
    
    return final_model_path


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="BART ëª¨ë¸ í•™ìŠµ")
    parser.add_argument("--config-path", type=str, default=None, 
                       help="ì„¤ì • íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--config-name", type=str, default="config.yaml",
                       help="ì„¤ì • íŒŒì¼ ì´ë¦„ (sweepìš©)")
    
    # WandB Sweepì—ì„œ ì „ë‹¬ë˜ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤
    parser.add_argument("--learning_rate", type=float, default=None,
                       help="í•™ìŠµë¥ ")
    parser.add_argument("--num_train_epochs", type=int, default=None,
                       help="í•™ìŠµ ì—í¬í¬ ìˆ˜")
    parser.add_argument("--weight_decay", type=float, default=None,
                       help="ê°€ì¤‘ì¹˜ ê°ì‡ ")
    parser.add_argument("--per_device_train_batch_size", type=int, default=None,
                       help="ë°°ì¹˜ í¬ê¸°")
    parser.add_argument("--gradient_accumulation_steps", type=int, default=None,
                       help="ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  ìŠ¤í…")
    parser.add_argument("--num_beams", type=int, default=None,
                       help="ë¹” ì„œì¹˜ ê°œìˆ˜")
    parser.add_argument("--dropout", type=float, default=None,
                       help="ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨")
    parser.add_argument("--warmup_ratio", type=float, default=None,
                       help="ì›Œë°ì—… ë¹„ìœ¨")
    parser.add_argument("--label_smoothing", type=float, default=None,
                       help="ë¼ë²¨ ìŠ¤ë¬´ë”© íŒ©í„°")
    parser.add_argument("--length_penalty", type=float, default=None,
                       help="ê¸¸ì´ í˜ë„í‹°")
    parser.add_argument("--repetition_penalty", type=float, default=None,
                       help="ë°˜ë³µ í˜ë„í‹°")
    
    args = parser.parse_args()
    
    # ëª…ë ¹ì¤„ ì¸ìë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (Noneì´ ì•„ë‹Œ ê°’ë“¤ë§Œ)
    sweep_overrides = {}
    if args.learning_rate is not None:
        sweep_overrides['learning_rate'] = args.learning_rate
    if args.num_train_epochs is not None:
        sweep_overrides['num_train_epochs'] = args.num_train_epochs
    if args.weight_decay is not None:
        sweep_overrides['weight_decay'] = args.weight_decay
    if args.per_device_train_batch_size is not None:
        sweep_overrides['per_device_train_batch_size'] = args.per_device_train_batch_size
    if args.gradient_accumulation_steps is not None:
        sweep_overrides['gradient_accumulation_steps'] = args.gradient_accumulation_steps
    if args.num_beams is not None:
        sweep_overrides['num_beams'] = args.num_beams
    if args.dropout is not None:
        sweep_overrides['dropout'] = args.dropout
    if args.warmup_ratio is not None:
        sweep_overrides['warmup_ratio'] = args.warmup_ratio
    if args.label_smoothing is not None:
        sweep_overrides['label_smoothing'] = args.label_smoothing
    if args.length_penalty is not None:
        sweep_overrides['length_penalty'] = args.length_penalty
    if args.repetition_penalty is not None:
        sweep_overrides['repetition_penalty'] = args.repetition_penalty
    
    # WandB sweep ëª¨ë“œ ë¹„í™œì„±í™”ë¨
    # sweep ëª¨ë“œëŠ” ë” ì´ìƒ ì§€ì›ë˜ì§€ ì•ŠìŒ
    elif sweep_overrides:
        # ëª…ë ¹ì¤„ì—ì„œ sweep íŒŒë¼ë¯¸í„°ê°€ ì „ë‹¬ëœ ê²½ìš°
        print("ğŸ”„ ëª…ë ¹ì¤„ Sweep íŒŒë¼ë¯¸í„°ë¡œ ì‹¤í–‰")
        main(args.config_path, sweep_overrides)
    else:
        # ì¼ë°˜ ì‹¤í–‰
        print("ğŸš€ ì¼ë°˜ í•™ìŠµ ëª¨ë“œë¡œ ì‹¤í–‰")
        main(args.config_path)
